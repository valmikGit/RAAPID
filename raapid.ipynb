{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern extraction and JSON generation complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Load the CSV dataset\n",
    "df = pd.read_csv(\"Task_B_Dataset.csv\")\n",
    "\n",
    "# Helper function to extract phrases matching the given pattern\n",
    "def extract_patterns(raw_text, pattern_type):\n",
    "    words_tags = raw_text.split()\n",
    "    pattern1_regex = re.compile(r\"(in/nn(?:/nn)*)\")\n",
    "    pattern2_regex = re.compile(r\"(jj/nn(?:/nn)*)\")\n",
    "\n",
    "    extracted_phrases = []\n",
    "    phrase_type = \"\"\n",
    "\n",
    "    # Iterate through the sentence\n",
    "    for i in range(len(words_tags)):\n",
    "        current_phrase = []\n",
    "        for j in range(i, len(words_tags)):\n",
    "            tag_sequence = [wt.split(\"/\")[1] for wt in words_tags[i:j+1]]\n",
    "            word_sequence = [wt.split(\"/\")[0] for wt in words_tags[i:j+1]]\n",
    "\n",
    "            # Check for Pattern 1: in + nn nn ...\n",
    "            if pattern_type == \"pattern 1\" and tag_sequence[0] == \"in\" and all(tag == \"nn\" for tag in tag_sequence[1:]):\n",
    "                phrase_type = \"in \" + \" \".join(tag_sequence[1:])\n",
    "                extracted_phrases.append({\n",
    "                    \"begin\": len(\" \".join(words_tags[:i])) + (1 if i > 0 else 0),\n",
    "                    \"end\": len(\" \".join(words_tags[:j+1])),\n",
    "                    \"text\": \" \".join(word_sequence),\n",
    "                    \"phrase_type\": phrase_type\n",
    "                })\n",
    "\n",
    "            # Check for Pattern 2: jj + nn nn ...\n",
    "            elif pattern_type == \"pattern 2\" and tag_sequence[0] == \"jj\" and all(tag == \"nn\" for tag in tag_sequence[1:]):\n",
    "                phrase_type = \"jj \" + \" \".join(tag_sequence[1:])\n",
    "                extracted_phrases.append({\n",
    "                    \"begin\": len(\" \".join(words_tags[:i])) + (1 if i > 0 else 0),\n",
    "                    \"end\": len(\" \".join(words_tags[:j+1])),\n",
    "                    \"text\": \" \".join(word_sequence),\n",
    "                    \"phrase_type\": phrase_type\n",
    "                })\n",
    "\n",
    "    # Select the largest matching phrase\n",
    "    if extracted_phrases:\n",
    "        extracted_phrases = sorted(extracted_phrases, key=lambda x: len(x[\"text\"]), reverse=True)\n",
    "        return [extracted_phrases[0]]  # Only select the largest match\n",
    "\n",
    "    return []\n",
    "\n",
    "# Process sentences to generate JSON output\n",
    "def generate_json_output(df, pattern_type):\n",
    "    results = {\n",
    "        \"pattern\": pattern_type,\n",
    "        \"sents\": []\n",
    "    }\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        filename, para_id, sent_id, raw_text = row[\"filename\"], row[\"para_id\"], row[\"sent_id\"], row[\"raw_text\"]\n",
    "        phrases = extract_patterns(raw_text, pattern_type)\n",
    "\n",
    "        if phrases:\n",
    "            sent_text = \" \".join([wt.split(\"/\")[0] for wt in raw_text.split()])\n",
    "\n",
    "            results[\"sents\"].append({\n",
    "                \"filename\": filename,\n",
    "                \"para_id\": para_id,\n",
    "                \"sent_id\": sent_id,\n",
    "                \"sent_text\": sent_text,\n",
    "                \"phrases\": phrases\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Generate JSON output for Pattern 1\n",
    "pattern1_results = generate_json_output(df, \"pattern 1\")\n",
    "\n",
    "# Generate JSON output for Pattern 2\n",
    "pattern2_results = generate_json_output(df, \"pattern 2\")\n",
    "\n",
    "# Save Pattern 1 results to JSON file\n",
    "with open(\"pattern1_results.json\", \"w\") as f1:\n",
    "    json.dump(pattern1_results, f1, indent=4)\n",
    "\n",
    "# Save Pattern 2 results to JSON file\n",
    "with open(\"pattern2_results.json\", \"w\") as f2:\n",
    "    json.dump(pattern2_results, f2, indent=4)\n",
    "\n",
    "print(\"Pattern extraction and JSON generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# # Define ground truth and predicted data for evaluation\n",
    "# def evaluate_results(true_data, pred_data):\n",
    "#     true_phrases = set((s[\"filename\"], s[\"para_id\"], s[\"sent_id\"], p[\"text\"]) \n",
    "#                        for s in true_data[\"sents\"] for p in s[\"phrases\"])\n",
    "#     pred_phrases = set((s[\"filename\"], s[\"para_id\"], s[\"sent_id\"], p[\"text\"]) \n",
    "#                        for s in pred_data[\"sents\"] for p in s[\"phrases\"])\n",
    "\n",
    "#     tp = len(true_phrases.intersection(pred_phrases))\n",
    "#     fp = len(pred_phrases - true_phrases)\n",
    "#     fn = len(true_phrases - pred_phrases)\n",
    "\n",
    "#     precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "#     recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "#     f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "#     return {\"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1}\n",
    "\n",
    "# # Load ground truth and predicted results for Pattern 1\n",
    "# with open(\"ground_truth_pattern1.json\") as gt1, open(\"pattern1_results.json\") as pred1:\n",
    "#     ground_truth1 = json.load(gt1)\n",
    "#     predicted1 = json.load(pred1)\n",
    "\n",
    "# # Evaluate Pattern 1\n",
    "# pattern1_eval = evaluate_results(ground_truth1, predicted1)\n",
    "# print(\"Pattern 1 Evaluation:\", pattern1_eval)\n",
    "\n",
    "# # Load ground truth and predicted results for Pattern 2\n",
    "# with open(\"ground_truth_pattern2.json\") as gt2, open(\"pattern2_results.json\") as pred2:\n",
    "#     ground_truth2 = json.load(gt2)\n",
    "#     predicted2 = json.load(pred2)\n",
    "\n",
    "# # Evaluate Pattern 2\n",
    "# pattern2_eval = evaluate_results(ground_truth2, predicted2)\n",
    "# print(\"Pattern 2 Evaluation:\", pattern2_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raapidenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
